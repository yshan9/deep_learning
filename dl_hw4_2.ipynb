{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_hw4-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNERrxQJ3CTqHZgK4oxFdHM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshan9/deep_learning/blob/master/dl_hw4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eycMxYOoPx5"
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyKNqj9qofwn"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4JCG33VoXyp"
      },
      "source": [
        "Load and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SinEELgQoTsk"
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTPKwLBgob0y"
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv9-MnY8ozCK"
      },
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iDjbjkBo1iD"
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JObuw4HBo5EI"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvufYmko-g1"
      },
      "source": [
        "The Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIc9BZhNo7yI"
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egOK1CYapEU6",
        "outputId": "5e3f76d5-290f-4d1f-a566-b16af3af8ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f607eb54f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYj0lEQVR4nO3de3DV1bUH8O8igArh/YgBogGKIqIIpHoFRIVi1bYidUTsjIWZFvqAKW2xV0fbqXY6HcYrVKcInYhUtF46MlSFFqSAIKKgRORZ3hGEFAhvMJFHYN0/cuykNnut9JzknDN3fz8zDOF82Tmbk7M4ydm/vbaoKojo/79GmZ4AEaUHi50oEix2okiw2IkiwWInikTjdN5Zbm6utmnTJpg3amT/33PhwoVglpOTk/TYurBWLbwVjaZNm5r5uXPnzLxxY/vLdPHiRTNPZexll11m5lVVVWYuIg0yti6sx817rqU6N+85YT1fz58/b461nssnTpxAZWVlrZNLqdhF5E4AzwLIATBTVSdbf79NmzaYNGlSML/kkkvM+zt16lQwa926tTn2xIkTZu598c6ePRvMvILp1KmTmZeVlZl5+/btzfzTTz8NZt6/68yZM2bes2dPM/ce1yZNmgSzI0eOJD0W8P8Dz8vLC2bef2LHjh0zc+8/YK9gmzdvHszKy8vNsVYdFBcXB7Okv40XkRwAzwG4C0AvAA+KSK9kPx8RNaxUfma/EcAuVS1V1XMA/gRgeP1Mi4jqWyrF3hnAvhp/3p+47V+IyDgRKRGRkoqKihTujohS0eDvxqtqsaoWqWqR9XMKETWsVIq9DEBBjT93SdxGRFkolWJfC6CHiHQVkaYARgGYXz/TIqL6lvTSm6pWicgEAItRvfQ2S1W3WGNExFyyOH36tHmf1lLMZ599Zo5t1qyZma9evdrMR44cGcyOHj1qjvWWmLw138LCQjN///33g1lubq45Nj8/38y9ZUNvCcpawvKuL+jSpYuZr1y50syt5VjvudauXTsz/+Mf/2jm999/v5lXVlYGM28Z2Zt7SErr7Kq6EMDCVD4HEaUHL5cligSLnSgSLHaiSLDYiSLBYieKBIudKBJp3c/eqFEjc73bW49OZS+8tUUVAPr372/m1jZWa4upNxYArrrqKjPftm2bma9ZsyaYffe73zXHrlixwswPHTpk5kOHDjXzjz/+OJh51wB4eym8Nf7S0tJg5m3NvfTSS828d+/eZu5tU3333XeD2V133WWO/cc//hHMrK21fGUnigSLnSgSLHaiSLDYiSLBYieKBIudKBJpXXoD7I6gx48fN8e2bNkymHnLdjfffLOZr1u3zsx37NgRzE6ePGmO9Tr0eMtAntGjRwczr0uq1z12+/btZj5/vt3CwNrG6j0urVq1MvPBgwebufVv97Y89+vXz8z37t1r5t7j1rVr12Dmza2goCCYWW3L+cpOFAkWO1EkWOxEkWCxE0WCxU4UCRY7USRY7ESRSOs6+8WLF82Wz9dee6053lo3HTRokDl2+fLlZu61VLbaWHvrot26dTNzqxU04LfJtto9X3311ebYXbt2mXmvXvZZnd46/jXXXBPMvHV0r0W3de0DYK/jeyfAeicKe6fjem2w33rrrWB26623mmOt56I1L76yE0WCxU4UCRY7USRY7ESRYLETRYLFThQJFjtRJLKqlbTHWrvct2+fOdZb0/XWmwcMGBDMvH3ZixcvNnOvXfOoUaPMfNq0acHM269++PBhM584caKZv/LKK2Zu7a+21osBf637sssuM/OdO3cGM6s3AuAfJ+21mp43b56ZX3fddcFswYIF5lirPfiLL74YzFIqdhHZA+A0gAsAqlS1KJXPR0QNpz5e2W9XVbtNDBFlHH9mJ4pEqsWuAP4mIh+KyLja/oKIjBOREhEpOX36dIp3R0TJSvXb+EGqWiYiHQEsEZFtqrqy5l9Q1WIAxQBQWFioKd4fESUppVd2VS1L/F4O4DUAN9bHpIio/iVd7CLSXERafP4xgDsAbK6viRFR/Url2/g8AK8l9s82BvC/qvqmNUBVzX3E3tHH1r7tmTNnmmPvvvtuM+/YsaOZq4Z/AvH2XXv79IcMGWLm1jG8APDNb34zmHnryd5x0N6/bfNm+//32267LZi999575tiBAweaed++fc38k08+CWZe/wJvDd973IqK7FVo67nu9T/YsmVLMLN6HyRd7KpaCqBPsuOJKL249EYUCRY7USRY7ESRYLETRYLFThSJrGol7R27vGHDhmCWk5NjjvW2LE6fPt3MH3744WDmLU95yzDekc1e22JrGeiee+4xx3pbMb1loC9/+ctmbrXwXrNmjTnW2347cuRIM7fm5j0fFi1aZObe8eI33XSTmf/+978PZs8//7w5dvfu3cHMqgO+shNFgsVOFAkWO1EkWOxEkWCxE0WCxU4UCRY7USTE2rpZ3zp37qzf//73g7l3vLDVhnrhwoXmWO/oYe8IX2sb6quvvmqOtdZFAb9lsrVNFADKy8uDWffu3c2xV1xxhZl7LbatbaSA/TX11rK9bcmnTp0y81WrVgWzMWPGmGO91uPeWnj79u3NvE2bNkllALBixYpgNm/ePBw+fLjWCzP4yk4UCRY7USRY7ESRYLETRYLFThQJFjtRJFjsRJFI+5HNVoteq0UuABQWFpqf27Jp0yYzHzZsmJnPnTs3mD3wwAPm2EmTJpm5d2Rz//79zdzacz516lRzbIsWLcz8mWeeMfPWrVub+c9+9rNgZn09Ab9V9IwZM8zcatfsXRvh7eP3jjLbs2ePmX/ta18LZqWlpebYDh06BDPrGGy+shNFgsVOFAkWO1EkWOxEkWCxE0WCxU4UCRY7USTSup+9U6dOOnbs2GDuHZNrrel6a7Zeb3avZ33v3r2D2Y4dO8yx3prttGnTzNw6qhoA8vLygpnX13379u1mfv3115v5X/7yFzO3rhGw1osBv6d948b2ZSLf+ta3gllxcbE51uv17/Xy37t3r5mXlJQEs0ceecQca33NpkyZgn379iW3n11EZolIuYhsrnFbWxFZIiI7E7/bu+2JKOPq8m38iwDu/MJtjwJYpqo9ACxL/JmIsphb7Kq6EsCxL9w8HMDsxMezAdxbz/MionqW7Bt0eap6IPHxQQDBHxpFZJyIlIhISWVlZZJ3R0SpSvndeK1+hy/4Lp+qFqtqkaoWWQ0jiahhJVvsh0QkHwASv4fbmxJRVki22OcDGJ34eDSAN+pnOkTUUNz97CIyB8BtANqLyH4AvwQwGcCrIvIdAHsB2AdlJzRr1szco/zmm2+a460e6G+//bY5dvDgwWZ++eWXm7nVP33t2rXmWI+3n33UqFFmPnPmzGC2c+dOc2zHjh3N3Ovd7vUJsD5/586dzbG/+c1vzPzpp58289dffz2YffTRR+ZY7/ngPd9Gjx5t5n369AlmXq9+6/lSVVUVzNxiV9UHA9FQbywRZQ9eLksUCRY7USRY7ESRYLETRYLFThSJtLaSrqiowAcffBDMvW2FVvvenJwc974t1jINAIwcGV5d9Fpgl5WVmbm3/TY3N9fMf/SjHwUzb+nNOx7Ym5vXUnngwIHB7A9/+IM51tsC6y3dWVuLvS3Rx48fN/N+/fqZ+S233GLm1pKltSwHAGfOnAlmVh3wlZ0oEix2okiw2IkiwWInigSLnSgSLHaiSLDYiSKR1nX2nJwcc133kksuMcdbrYM//vhjc+yqVavM3Dse2GoN7B3Pax0dDABf/epXzbxHjx5mvmTJkmB28OBBc+zJkyfN3OsuNGHCBDP/5JNPgtmgQYPMsd51F2fPnjXzl156KZidO3fOHHvPPfeYuXdM9y9+8Qszt76m3rURzZs3D2ZWi2u+shNFgsVOFAkWO1EkWOxEkWCxE0WCxU4UCRY7USTSus7eqFEj81hm75jbixcvBrMrrrjCHNuzZ08zX79+vZlb+5+7du1qjvX22nvHRT/55JNm3rZt22A2ZMgQc+zSpUvNfNmyZWbutVxu3759MHvnnXfMsd5+9RdeeMHMb7311mC2YcMGc6zX3ru0tNTMrX38gH1ks7ef/dSpU8HswoULwYyv7ESRYLETRYLFThQJFjtRJFjsRJFgsRNFgsVOFIm0rrOLiLkn3euvbvXi9o65nTt3rpkfPXrUzJs0aWLmFuvfDPh7yidPnmzmM2bMCGaVlZXmWG9P+X333WfmP/nJT8zcWiu/6aabzLGfffaZmQ8bNszMrT4DX//6182x3jq71yegZcuWZm6tlXt1cP78+WBmHdnsvrKLyCwRKReRzTVue0JEykRkfeKXfYg3EWVcXb6NfxHAnbXc/ltVvSHxa2H9TouI6ptb7Kq6EsCxNMyFiBpQKm/QTRCRjYlv84ON5URknIiUiEiJ14uNiBpOssU+A0B3ADcAOABgSugvqmqxqhapapF3QCERNZykil1VD6nqBVW9COB5ADfW77SIqL4lVewikl/jjyMAbA79XSLKDu46u4jMAXAbgPYish/ALwHcJiI3AFAAewB8ry53pqrmGuF1111njrfO6169erU5tqCgwMy9vdPWOeVbt241x44dO9bMrT7gADB9+nQz79WrVzBTVXPsRx99ZOZeT3xrvRgAmjZtGsy8vfCLFy82c2/8xIkTg9mzzz5rjvV69VdUVJh5q1atzNy6vsF7rr788svBzOqH7xa7qj5Yy8121wAiyjq8XJYoEix2okiw2IkiwWInigSLnSgSad3i2rhxY/PIZm9L4759+4LZvffea4599913zdxqFQ0Al156aTDzWmB7W1gXLFhg5uPHjzfzKVOCFzC6Y6+88koz79atm5l7LZlbtGiR9Nj8/Hwzb926tZkvX748mHnHIntbnq323QCwfft2M7f+7d4StHUc9JgxY4IZX9mJIsFiJ4oEi50oEix2okiw2IkiwWInigSLnSgS4m2BrE+FhYX6+OOPB3PruFnAXof31roHDBhg5p06dTJza53dO3rYOqYasI81BvzHZf/+/Q1239u2bTNzb4vr0KFDg9lTTz1ljn3ggQfM3NrOCVQfER7itdj2HjdvW7J1fQEA7N69O5h57duaNWsWzJ577jmUlZVJbRlf2YkiwWInigSLnSgSLHaiSLDYiSLBYieKBIudKBJp3c9eVVWFY8fCx8Z5a+UjRowIZqWlpeZYL1+6dKmZW/vlN23aZI719oR7x01ba9VA9VHYIUeOHDHH/u53vzPzqVOnmvmvf/1rM8/JyQlm3lp1v379zHz9+vVJ59Yx14B/ZLN3jLb3NX/jjTeCmdebwbu+IISv7ESRYLETRYLFThQJFjtRJFjsRJFgsRNFgsVOFIm0rrOrqrk3u3///uZ4a+3T25d99uxZM2/ZsqWZnzlzJpjdfPPN5livh7h3DcDgwYPNfPPmzcHsS1/6kjm2Xbt2Zu5dQ/Dwww+bubUmbF0fAPh7zufNm2fm3/jGN4KZd+3C22+/bebeNQJXX321mQ8fPjyYef3yV6xYEcys57n7yi4iBSKyXET+LiJbRGRi4va2IrJERHYmfg+f/kBEGVeXb+OrAExS1V4A/gvAeBHpBeBRAMtUtQeAZYk/E1GWcotdVQ+o6rrEx6cBbAXQGcBwALMTf202APsaPyLKqP/oDToRKQTQF8D7APJU9UAiOgggLzBmnIiUiEhJRUVFClMlolTUudhFJBfAPAA/VtV/6TKo1V0ra+1cqarFqlqkqkXemxpE1HDqVOwi0gTVhf6Kqv45cfMhEclP5PkAyhtmikRUH9xW0lK9PjIbwDFV/XGN2/8HwFFVnSwijwJoq6r/bX2uLl266MSJE4O5twx04sSJYOYtnS1evNjMvS2J1hG93n1ffvnlZn7w4EEzX7RokZm3atUqmHkttL3H3Mtfe+01My8oKAhm3rHH3nNz5MiRZv7kk08Gsw4dOphjrdbhgL8N9ec//7mZW63LrRbYADBw4MBgNmnSJOzatavWNc26rLMPBPAQgE0i8vkG4ccATAbwqoh8B8BeAPYjT0QZ5Ra7qq4CELr6wb4ygYiyBi+XJYoEi50oEix2okiw2IkiwWInikRaj2wuKCjQn/70p8HcO6rWWvM9fPiwOdbbTjlkyBAzt44m3rFjhznW2377wQcfmHnnzp3N3Fpnv+aaa8yxc+bMMXPvuOg+ffqYuTX39957zxzrPR9yc3OTvm/vc5eVlZm51RIdAO677z4zP3r0aDDznqvLli0zs2PHjvHIZqKYsdiJIsFiJ4oEi50oEix2okiw2IkiwWInikRaW0mLCJo0aRLMN2zYYI5/4okngtkzzzxjjv3BD35g5t66qHVEr3X8LgA89NBDZr569WoznzlzpplbxyZbLbABYO3atWbutcl+/fXXzdxa677++uvNsVb/AsBv53z+/Plg1qJFC3Osd6Szdb0I4O9Jb9asWTDLy6u1w9s/WW2wrWs2+MpOFAkWO1EkWOxEkWCxE0WCxU4UCRY7USRY7ESRSOs6u2f06NFmvnz58mDWtGlTc6y3Hnz//febubVe7e3pXrNmjZl7R1Xv27fPzK2eBF/5ylfMsW+99ZaZe+vJf/3rX83c+rp4j8sPf/hDM/d6GFhr3daxx4D9XAOAa6+91sw3btxo5tbzyTtnwHrMT548Gcz4yk4UCRY7USRY7ESRYLETRYLFThQJFjtRJFjsRJFw19lFpADASwDyACiAYlV9VkSeADAWwOeLnY+p6kLrc6kqzp49G8x37txpzsXq9e31EL/99tvN3NpfDACzZs1K+r73799v5mPGjDFzbz15woQJwcy7vmDw4MFmXlJSYubeOebWuu9jjz2W9FgAWLx4sZl37do1mG3fvt0c6/U38Prp5+fnm7m1n977evft2zeYffjhh8GsLhfVVAGYpKrrRKQFgA9FZEki+62qPl2Hz0FEGVaX89kPADiQ+Pi0iGwFYB9RQkRZ5z/6mV1ECgH0BfB+4qYJIrJRRGaJSJvAmHEiUiIiJRUVFSlNloiSV+diF5FcAPMA/FhVTwGYAaA7gBtQ/co/pbZxqlqsqkWqWuT1DCOihlOnYheRJqgu9FdU9c8AoKqHVPWCql4E8DyAGxtumkSUKrfYpfpIyRcAbFXVqTVur/l24wgAm+t/ekRUX9wjm0VkEIB3AGwCcDFx82MAHkT1t/AKYA+A7yXezAvq1q2b/upXvwrmXutga5lnz5495ljrWGMAuOWWW8zcahftbXFt3Nh+H9RqeVwXVjvoO+64wxxbXl5u5lu3bjXz8ePHm/mCBQuCmfc1Wbp0qZlfddVVZt69e/dg5n1NVq5caebecuqAAQPM3NriWllZaY49ffp0MJszZw4OHTpU65HNdXk3fhWA2gaba+pElF14BR1RJFjsRJFgsRNFgsVOFAkWO1EkWOxEkUhrK+mqqiocP348mK9bt84cP2LEiGDmbY+1ttYCwPz585O+70WLFpljve2zBw6Ylydg3LhxZr5p06ZgduTIEXPs3LlzzdxrRe0dld2zZ89gNn36dHPstGnTzLy4uNjMjx49Gsxmz55tjv32t79t5gUFBWZuPc8B+xoAb9uwVSfV18DVjq/sRJFgsRNFgsVOFAkWO1EkWOxEkWCxE0WCxU4UCXc/e73emchhAHtr3NQegL0QnDnZOrdsnRfAuSWrPud2pap2qC1Ia7H/252LlKhqUcYmYMjWuWXrvADOLVnpmhu/jSeKBIudKBKZLnb74ubMyta5Zeu8AM4tWWmZW0Z/Ziei9Mn0KzsRpQmLnSgSGSl2EblTRLaLyC4ReTQTcwgRkT0isklE1ouIfV5xw89lloiUi8jmGre1FZElIrIz8XutZ+xlaG5PiEhZ4rFbLyJ3Z2huBSKyXET+LiJbRGRi4vaMPnbGvNLyuKX9Z3YRyQGwA8AwAPsBrAXwoKr+Pa0TCRCRPQCKVDXjF2CIyGAAnwJ4SVV7J257CsAxVZ2c+I+yjao+kiVzewLAp5k+xjtxWlF+zWPGAdwLYAwy+NgZ8xqJNDxumXhlvxHALlUtVdVzAP4EYHgG5pH1VHUlgGNfuHk4gM/brMxG9ZMl7QJzywqqekBV1yU+Pg3g82PGM/rYGfNKi0wUe2cA+2r8eT+y67x3BfA3EflQROx+UJmRV+OYrYMA8jI5mVq4x3in0xeOGc+axy6Z489TxTfo/t0gVe0H4C4A4xPfrmYlrf4ZLJvWTut0jHe61HLM+D9l8rFL9vjzVGWi2MsA1OzW1yVxW1ZQ1bLE7+UAXkP2HUV96PMTdBO/2yczplE2HeNd2zHjyILHLpPHn2ei2NcC6CEiXUWkKYBRAOzWrmkiIs0Tb5xARJoDuAPZdxT1fACjEx+PBhA+XjbNsuUY79Ax48jwY5fx489VNe2/ANyN6nfkdwN4PBNzCMyrG4ANiV9bMj03AHNQ/W3deVS/t/EdAO0ALAOwE8BSAG2zaG4vo/po742oLqz8DM1tEKq/Rd8IYH3i192ZfuyMeaXlcePlskSR4Bt0RJFgsRNFgsVOFAkWO1EkWOxEkWCxE0WCxU4Uif8DT6Ztd+dWEZEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6kj4CDpJ6d"
      },
      "source": [
        "The Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZClVjZcOpHdM"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsG56Ei1pNnH",
        "outputId": "add1d5d1-3375-4f2a-e932-6685c764bded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.00106795]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJjElik8pSu2"
      },
      "source": [
        "Define Loss and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdXnHVOkpWWP"
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1G9RK8EpkT9"
      },
      "source": [
        "Discriminator Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzKF9d4kphs9"
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR4Q8mlwpqOd"
      },
      "source": [
        "Generator Loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EkEd4A3p3TR"
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-YTzv9p4OE"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYM8jWVqp8BV"
      },
      "source": [
        "Save Check Points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8aq28JKp-Ek"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xy_KXiAqBAQ"
      },
      "source": [
        "Define the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m-a7FHSqJP0"
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WplB2NjPqKYU"
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcWXRwlqN4Q"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pi2cYXEqRbt"
      },
      "source": [
        "Generate and save images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqu5x86MqT94"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AAfIrVZqi3g"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsGK-C5NqYKl"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMR47-4qqH5",
        "outputId": "029de144-6560-457b-b763-744488263c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f607d27dba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwP3v-aql3D"
      },
      "source": [
        "Create a GIF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxiPeMClquiI"
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxqD1lVNqxbV"
      },
      "source": [
        "display_image(EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utxW4y2Nqzqb"
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_kxSeogq3O7"
      },
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}